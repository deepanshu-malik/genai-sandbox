{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings & Semantic Search Demo\n",
    "\n",
    "This notebook demonstrates how embeddings work for semantic search - the foundation of RAG systems.\n",
    "\n",
    "**Workflow:**\n",
    "1. **Run cells 1-3 once** to create embeddings (costs tokens)\n",
    "2. **Run cell 4 multiple times** to test different questions (free!)\n",
    "\n",
    "This saves you money while experimenting! üí∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup & Imports\n",
    "Run this once at the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Setup complete!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "print(\"‚úì Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Helper Functions\n",
    "Functions for embeddings and similarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"Convert text to embedding vector\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate similarity between two vectors (0-1 scale, 1=most similar)\"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    magnitude = np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
    "    return dot_product / magnitude\n",
    "\n",
    "def find_most_relevant(question_embedding, doc_embeddings, documents, top_k=3):\n",
    "    \"\"\"Find top_k most relevant documents for a question\"\"\"\n",
    "    similarities = []\n",
    "    for i, doc_emb in enumerate(doc_embeddings):\n",
    "        score = cosine_similarity(question_embedding, doc_emb)\n",
    "        similarities.append((score, i, documents[i]))\n",
    "    \n",
    "    # Sort by similarity (highest first)\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:top_k]\n",
    "\n",
    "print(\"‚úì Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Create Document Embeddings\n",
    "\n",
    "**RUN THIS ONCE** - Creates embeddings for all documents.\n",
    "\n",
    "üí° **Tip:** You can modify the `documents` list to add your own test documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for 8 documents...\n",
      "(This costs tokens, but we only do it once!)\n",
      "\n",
      "  [1/8] Embedded: Employees receive 15 days of PTO annually. This in...\n",
      "  [2/8] Embedded: Our remote work policy allows employees to work fr...\n",
      "  [3/8] Embedded: The database uses PostgreSQL 14 with automatic bac...\n",
      "  [4/8] Embedded: Time off requests must be submitted 2 weeks in adv...\n",
      "  [5/8] Embedded: All employees must complete cybersecurity training...\n",
      "  [6/8] Embedded: The company matches 401k contributions up to 6% of...\n",
      "  [7/8] Embedded: Office hours are 9 AM to 6 PM, with flexible start...\n",
      "  [8/8] Embedded: Health insurance coverage begins on the first day ...\n",
      "\n",
      "‚úì Created 8 embeddings!\n",
      "  Each embedding has 1536 dimensions\n",
      "\n",
      "üí∞ Cost: ~$0.000160 (very cheap!)\n",
      "\n",
      "üéØ Now you can ask unlimited questions in Cell 4 without additional embedding costs!\n"
     ]
    }
   ],
   "source": [
    "# Your knowledge base - modify these to test with your own documents!\n",
    "documents = [\n",
    "    \"Employees receive 15 days of PTO annually. This includes vacation and sick leave.\",\n",
    "    \"Our remote work policy allows employees to work from home 3 days per week.\",\n",
    "    \"The database uses PostgreSQL 14 with automatic backups every 6 hours.\",\n",
    "    \"Time off requests must be submitted 2 weeks in advance through the HR portal.\",\n",
    "    \"All employees must complete cybersecurity training within their first month.\",\n",
    "    \"The company matches 401k contributions up to 6% of salary.\",\n",
    "    \"Office hours are 9 AM to 6 PM, with flexible start times between 8-10 AM.\",\n",
    "    \"Health insurance coverage begins on the first day of employment.\"\n",
    "]\n",
    "\n",
    "print(f\"Creating embeddings for {len(documents)} documents...\")\n",
    "print(\"(This costs tokens, but we only do it once!)\\n\")\n",
    "\n",
    "# Create embeddings for all documents\n",
    "doc_embeddings = []\n",
    "for i, doc in enumerate(documents):\n",
    "    embedding = get_embedding(doc)\n",
    "    doc_embeddings.append(embedding)\n",
    "    print(f\"  [{i+1}/{len(documents)}] Embedded: {doc[:50]}...\")\n",
    "\n",
    "print(f\"\\n‚úì Created {len(doc_embeddings)} embeddings!\")\n",
    "print(f\"  Each embedding has {len(doc_embeddings[0])} dimensions\")\n",
    "print(f\"\\nüí∞ Cost: ~${len(documents) * 0.00002:.6f} (very cheap!)\")\n",
    "print(\"\\nüéØ Now you can ask unlimited questions in Cell 4 without additional embedding costs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Ask Questions (Run Multiple Times!)\n",
    "\n",
    "**Change the `question` and re-run this cell** as many times as you want.\n",
    "\n",
    "No additional embedding costs - we already have the document embeddings! üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: When does my health insurance end?\n",
      "================================================================================\n",
      "\n",
      "üìä RELEVANCE SCORES:\n",
      "\n",
      "#1 - Score: 0.482\n",
      "    Doc [7]: Health insurance coverage begins on the first day of employment.\n",
      "\n",
      "#2 - Score: 0.194\n",
      "    Doc [3]: Time off requests must be submitted 2 weeks in advance through the HR portal.\n",
      "\n",
      "#3 - Score: 0.185\n",
      "    Doc [0]: Employees receive 15 days of PTO annually. This includes vacation and sick leave.\n",
      "\n",
      "================================================================================\n",
      "üìÑ SENDING TO LLM (most relevant doc only):\n",
      "\n",
      "  Health insurance coverage begins on the first day of employment.\n",
      "\n",
      "================================================================================\n",
      "ü§ñ LLM RESPONSE:\n",
      "\n",
      "  The provided context does not contain information about when your health insurance ends.\n",
      "\n",
      "================================================================================\n",
      "üí∞ COST: 68 tokens = $0.000010\n",
      "\n",
      "‚ú® Try changing the question above and re-running this cell!\n"
     ]
    }
   ],
   "source": [
    "# üîß CHANGE THIS QUESTION AND RE-RUN!\n",
    "# question = \"How many vacation days do I get?\"\n",
    "\n",
    "# Alternative questions to try:\n",
    "# question = \"Can I work from home for 5 days in a month?\"\n",
    "question = \"When does my health insurance end?\"\n",
    "# question = \"Tell me about retirement benefits\"\n",
    "# question = \"What database do we use and why?\"\n",
    "\n",
    "print(f\"‚ùì Question: {question}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Convert question to embedding\n",
    "question_embedding = get_embedding(question)\n",
    "\n",
    "# Find most relevant documents\n",
    "top_results = find_most_relevant(question_embedding, doc_embeddings, documents, top_k=3)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nüìä RELEVANCE SCORES:\\n\")\n",
    "for rank, (score, idx, doc) in enumerate(top_results, 1):\n",
    "    print(f\"#{rank} - Score: {score:.3f}\")\n",
    "    print(f\"    Doc [{idx}]: {doc}\")\n",
    "    print()\n",
    "\n",
    "# Use the most relevant document for RAG\n",
    "most_relevant_doc = top_results[0][2]\n",
    "print(\"=\" * 80)\n",
    "print(\"üìÑ SENDING TO LLM (most relevant doc only):\\n\")\n",
    "print(f\"  {most_relevant_doc}\\n\")\n",
    "\n",
    "# Generate answer using RAG\n",
    "print(\"=\" * 80)\n",
    "print(\"ü§ñ LLM RESPONSE:\\n\")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Answer the question based only on the provided context. If the context doesn't contain the answer, say so.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Context: {most_relevant_doc}\\n\\nQuestion: {question}\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(f\"  {answer}\\n\")\n",
    "\n",
    "# Show token usage\n",
    "tokens_used = response.usage.total_tokens\n",
    "cost = tokens_used * 0.00000015  # gpt-4o-mini pricing\n",
    "print(\"=\" * 80)\n",
    "print(f\"üí∞ COST: {tokens_used} tokens = ${cost:.6f}\")\n",
    "print(\"\\n‚ú® Try changing the question above and re-running this cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Compare Multiple Questions (Optional)\n",
    "\n",
    "Run this to see how different questions match to documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç TESTING MULTIPLE QUESTIONS\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚ùì Q: How many vacation days do I get?\n",
      "‚úì Best Match (score: 0.551): Employees receive 15 days of PTO annually. This includes vacation and ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚ùì Q: Can I work remotely?\n",
      "‚úì Best Match (score: 0.610): Our remote work policy allows employees to work from home 3 days per w...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚ùì Q: What database technology do we use?\n",
      "‚úì Best Match (score: 0.441): The database uses PostgreSQL 14 with automatic backups every 6 hours....\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚ùì Q: When does insurance coverage begin?\n",
      "‚úì Best Match (score: 0.765): Health insurance coverage begins on the first day of employment....\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test multiple questions at once\n",
    "test_questions = [\n",
    "    \"How many vacation days do I get?\",\n",
    "    \"Can I work remotely?\",\n",
    "    \"What database technology do we use?\",\n",
    "    \"When does insurance coverage begin?\"\n",
    "]\n",
    "\n",
    "print(\"üîç TESTING MULTIPLE QUESTIONS\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for q in test_questions:\n",
    "    q_emb = get_embedding(q)\n",
    "    top = find_most_relevant(q_emb, doc_embeddings, documents, top_k=1)[0]\n",
    "    score, idx, doc = top\n",
    "    \n",
    "    print(f\"\\n‚ùì Q: {q}\")\n",
    "    print(f\"‚úì Best Match (score: {score:.3f}): {doc[:70]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "1. **Embeddings capture meaning** - \"vacation\" matches \"PTO\" even with different words\n",
    "2. **One-time cost** - Embed documents once, query many times\n",
    "3. **Semantic search** - Finds relevant content based on meaning, not keywords\n",
    "4. **Token efficiency** - Only send relevant docs to LLM, not everything\n",
    "\n",
    "## üöÄ This is RAG!\n",
    "\n",
    "You just experienced the core of RAG:\n",
    "- **R**etrieval: Find relevant docs using embeddings\n",
    "- **A**ugmented: Add those docs to the prompt\n",
    "- **G**eneration: LLM generates answer based on retrieved context\n",
    "\n",
    "## üìù Experiment Ideas\n",
    "\n",
    "1. Add your own documents to the `documents` list in Cell 3\n",
    "2. Try questions that don't match any document - see how scores drop\n",
    "3. Modify `top_k` to send multiple documents to the LLM\n",
    "4. Compare costs: RAG vs sending all documents every time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
